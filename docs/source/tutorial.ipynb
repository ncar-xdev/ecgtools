{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, import `ecgtools`, and instantiate a builder object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecgtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `Builder` class expects:\n",
    "ecgtools.Builder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = ecgtools.Builder(\n",
    "    root_path=\"../../sample_data/cmip/CMIP6/\",\n",
    "    extension=\"*.nc\",\n",
    "    depth=4,\n",
    "    exclude_patterns=[\"*/files/*\", \"*/latest/*\"],\n",
    ")\n",
    "builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser\n",
    "\n",
    "Let's create a custom function for parsing the global attributes and variable\n",
    "attributes of an xarray dataset. For our use case, an xarray dataset corresponds\n",
    "to the content of a single netCDF file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some global attributes to extract from the xarray.dataset\n",
    "global_attrs = [\n",
    "    \"activity_id\",\n",
    "    \"institution_id\",\n",
    "    \"source_id\",\n",
    "    \"experiment_id\",\n",
    "    \"table_id\",\n",
    "    \"frequency\",\n",
    "    \"grid_label\",\n",
    "    \"realm\",\n",
    "    \"variable_id\",\n",
    "    \"variant_label\",\n",
    "    \"parent_experiment_id\",\n",
    "    \"parent_variant_label\",\n",
    "    \"sub_experiment\",\n",
    "]\n",
    "\n",
    "# Define variable attributes to extract from xarray.dataset\n",
    "variable_attrs = [\"standard_name\"]\n",
    "\n",
    "# We want to rename the following attributes once we've extracted their values\n",
    "attrs_mapping = {\n",
    "    \"variant_label\": \"member_id\",\n",
    "    \"parent_variant_label\": \"parent_member_id\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "\n",
    "def cmip6_ds_parser(\n",
    "    filepath: str,\n",
    "    global_attrs: list,\n",
    "    variable_attrs: list = None,\n",
    "    attrs_mapping: dict = None,\n",
    "    add_dim: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Function that harvests global attributes and variable attributes\n",
    "    for CMIP6 netCDF output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        filepath\n",
    "    global_attrs : list\n",
    "        global attributes to extract from the netCDF file.\n",
    "    variable_attrs : list, optional\n",
    "        variable attributes to extract from the netCDF file, by default None\n",
    "    attrs_mapping : dict, optional\n",
    "        A mapping to use to rename some keys/attributes harvested from\n",
    "        the netCDF file, by default None\n",
    "    add_dim : bool, optional\n",
    "        Whether to add variable's dimensionality information to harvested\n",
    "        attributes, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary of attributes harvested from the input CMIP6 netCDF file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = {\"path\": filepath}\n",
    "        ds = xr.open_dataset(\n",
    "            filepath, decode_times=True, use_cftime=True, chunks={}\n",
    "        )\n",
    "        g_attrs = ds.attrs\n",
    "        variable_id = g_attrs[\"variable_id\"]\n",
    "        v_attrs = ds[variable_id].attrs\n",
    "        for attr in global_attrs:\n",
    "            results[attr] = g_attrs.get(attr, None)\n",
    "\n",
    "        if variable_attrs:\n",
    "            for attr in variable_attrs:\n",
    "                results[attr] = v_attrs.get(attr, None)\n",
    "\n",
    "        # Is this a reliable way to get dim?\n",
    "        results[\"dim\"] = f\"{ds[variable_id].data.ndim}D\"\n",
    "\n",
    "        if \"time\" in ds.coords:\n",
    "            times = ds[\"time\"]\n",
    "            start = times[0].dt.strftime(\"%Y-%m-%d\").data.item()\n",
    "            end = times[-1].dt.strftime(\"%Y-%m-%d\").data.item()\n",
    "            results[\"end\"] = end\n",
    "            results[\"start\"] = start\n",
    "        if attrs_mapping and isinstance(attrs_mapping, dict):\n",
    "            for old_key, new_key in attrs_mapping.items():\n",
    "                results[new_key] = results.pop(old_key)\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        # TODO: Record faulty files\n",
    "        data = {\"exception\": str(e), \"file\": filepath}\n",
    "        print(data)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When parsing file attributes, `ecgtools` requires that the parser is a function\n",
    "with the following signature:\n",
    "\n",
    "```python\n",
    "def myparser(filepath, global_attrs):\n",
    "    ...\n",
    "```\n",
    "\n",
    "To meet this requirement, we need to modify our `cmip6_ds_parser` function by\n",
    "creating a partial function. A partial functions allow one to derive a function\n",
    "with x parameters to a function with fewer parameters and fixed values set for\n",
    "the more limited function (which is what `ecgtools` expects).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a partial for our parser\n",
    "import functools\n",
    "\n",
    "cmip6_parser = functools.partial(\n",
    "    cmip6_ds_parser, variable_attrs=variable_attrs, attrs_mapping=attrs_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl directories, compile list of files, and extract attributes\n",
    "\n",
    "Now we are ready to compile the list of valid file by crawling directories. Once\n",
    "we have this list of files, we should be able to extract attributes from each\n",
    "one as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    builder.parse_files_attributes(\n",
    "        global_attrs, parser=cmip6_parser, lazy=False\n",
    "    )  # Extract attributes from each file\n",
    "    .to_df()  # Create Pandas DataFrame containing all attributes extracted from the files\n",
    "    .df  # Retrieve constructed Pandas DataFrame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
